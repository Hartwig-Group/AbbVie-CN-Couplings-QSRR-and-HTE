{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "The following code is used to remove highly correlated features from the dataset. As well, ARFS (all relevant feature selection) is used to select the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../../data/ligand-qsar/raw/alkylamine-ligand-modeling-unprocessed.tsv\", sep=\"\\t\")\n",
    "# df = df[df[\"buchwald-type\"] > 0]\n",
    "# df = df[~df[\"ligand_1_name\"].isin([\"L-149\", \"L-150\"])]\n",
    "\n",
    "# Define bins and labels\n",
    "bins = [-np.inf, 15, np.inf]\n",
    "labels = [0, 1]\n",
    "transformer = preprocessing.FunctionTransformer(pd.cut, kw_args={\"bins\": bins, \"labels\": labels, \"retbins\": False})\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = df.drop(columns=[\"ligand_1_name\", \"product_1_yield\", \"buchwald-type\"])\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Transform target\n",
    "y = df[\"product_1_yield\"]\n",
    "y_bin = transformer.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def calcDrop(res: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Calculate which columns to drop based on correlation matrix.\"\"\"\n",
    "    # All variables with correlation > cutoff\n",
    "    all_corr_vars = list(set(res[\"v1\"].tolist() + res[\"v2\"].tolist()))\n",
    "\n",
    "    # All unique variables in drop column\n",
    "    poss_drop = list(set(res[\"drop\"].tolist()))\n",
    "\n",
    "    # Keep any variable not in drop column\n",
    "    keep = list(set(all_corr_vars).difference(set(poss_drop)))\n",
    "\n",
    "    # Drop any variables in same row as a keep variable\n",
    "    p = res[res[\"v1\"].isin(keep) | res[\"v2\"].isin(keep)][[\"v1\", \"v2\"]]\n",
    "    q = list(set(p[\"v1\"].tolist() + p[\"v2\"].tolist()))\n",
    "    drop = list(set(q).difference(set(keep)))\n",
    "\n",
    "    # Remove drop variables from possible drop\n",
    "    poss_drop = list(set(poss_drop).difference(set(drop)))\n",
    "\n",
    "    # subset res dataframe to include possible drop pairs\n",
    "    m = res[res[\"v1\"].isin(poss_drop) | res[\"v2\"].isin(poss_drop)][[\"v1\", \"v2\", \"drop\"]]\n",
    "\n",
    "    # remove rows that are decided (drop), take set and add to drops\n",
    "    more_drop = set(list(m[~m[\"v1\"].isin(drop) & ~m[\"v2\"].isin(drop)][\"drop\"]))\n",
    "    for item in more_drop:\n",
    "        drop.append(item)\n",
    "\n",
    "    return drop\n",
    "\n",
    "\n",
    "def corrX_new(df: pd.DataFrame, cut: float = 0.9):\n",
    "    \"\"\"Calculate the correlation matrix and return the columns to drop.\"\"\"\n",
    "    corr_mtx = df.corr().abs()\n",
    "    avg_corr = corr_mtx.mean(axis=1)\n",
    "    up = corr_mtx.where(np.triu(np.ones(corr_mtx.shape), k=1).astype(bool))\n",
    "\n",
    "    dropcols = []\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for row in range(len(up) - 1):\n",
    "        col_idx = row + 1\n",
    "        for col in range(col_idx, len(up)):\n",
    "            if corr_mtx.iloc[row, col] > cut:\n",
    "                if avg_corr.iloc[row] > avg_corr.iloc[col]:\n",
    "                    dropcols.append(row)\n",
    "                    drop = corr_mtx.columns[row]\n",
    "                else:\n",
    "                    dropcols.append(col)\n",
    "                    drop = corr_mtx.columns[col]\n",
    "\n",
    "                s = [\n",
    "                    corr_mtx.index[row],\n",
    "                    up.columns[col],\n",
    "                    avg_corr.iloc[row],\n",
    "                    avg_corr.iloc[col],\n",
    "                    up.iloc[row, col],\n",
    "                    drop,\n",
    "                ]\n",
    "\n",
    "                res.append(s)\n",
    "\n",
    "    res = pd.DataFrame(res, columns=([\"v1\", \"v2\", \"v1.target\", \"v2.target\", \"corr\", \"drop\"]))\n",
    "\n",
    "    dropcols_names = calcDrop(res)\n",
    "\n",
    "    return dropcols_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P_int_ipso_carbon', 'P_int_ligand', 'P_int_phosphine', 'buried_volume_ipso_2.5A', 'buried_volume_ipso_3.5A', 'buried_volume_ipso_4.5A', 'cone_angle', 'distance_Pd_P', 'global_electrophilicity', 'max_bond_order_Pd_P', 'max_buried_volume_ipso_4.5A', 'max_cone_angle', 'max_fukui_f_plus_aryl_carbon', 'max_global_nucleophilicity', 'max_mlep_Pd_C', 'max_mlep_Pd_N', 'max_mlep_Pd_O', 'max_mlep_Pd_P', 'max_pyramidalization_P', 'max_quadrant_buried_volume_ligand_min', 'max_quadrant_total_volume_ligand_range_max', 'max_sasa_ligand_volume', 'max_solid_angle', 'max_tolman_electronic_parameter', 'min_P_int_ligand', 'min_bond_order_Pd_P', 'min_buried_volume_3.5A', 'min_buried_volume_5.0A', 'min_buried_volume_ipso_4.5A', 'min_cone_angle', 'min_distance_Pd_N', 'min_global_electrophilicity', 'min_mlep_Pd_C', 'min_mlep_Pd_O', 'min_pyramidalization_P', 'min_quadrant_buried_volume_ligand_min', 'min_quadrant_total_volume_ligand_min', 'min_sasa_ligand_area', 'min_sasa_ligand_volume', 'min_solid_angle', 'mlep_Pd_N', 'mlep_Pd_P', 'pyramidalization_P', 'quadrant_buried_volume_ligand_min', 'quadrant_total_volume_ligand_max', 'sasa_ligand_area', 'sasa_ligand_volume', 'sasa_phosphine_area', 'solid_angle', 'sterimol_ligand_L', 'tolman_electronic_parameter']\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "run = True\n",
    "\n",
    "if run:\n",
    "    drop_cols = corrX_new(X, cut=0.95)\n",
    "\n",
    "    X = X.drop(columns=drop_cols)\n",
    "\n",
    "    print(sorted(drop_cols))\n",
    "    print(len(drop_cols))\n",
    "\n",
    "    df = df.drop(columns=drop_cols)\n",
    "    df.to_csv(\"../../data/ligand-qsar/alkylamine-ligand-modeling.tsv\", sep=\"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abbvie-cn-couplings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
